{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "22NKuno-qtbv",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kriBNwPMqtbz"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "import random\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from hyperopt import fmin, tpe, hp\n",
    "import time\n",
    "import copy\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "AwfgfyPdqtb4",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# Check Available Devices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_xdHa9xQqtb4",
    "outputId": "b6805a70-2f18-47f3-e7b2-ba1c4a4a831b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available:\n",
    "  avDev = torch.device(\"cuda\")\n",
    "else:\n",
    "  avDev = torch.device(\"cpu\")\n",
    "print(avDev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "r-hP4do1qtb7",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# Set Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XNpBgXb6qtb8"
   },
   "outputs": [],
   "source": [
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.backends.cudnn.deterministic=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "rtv7fnvYqtcA",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# Utility for Displaying Images, Error Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZYAs2u4UqtcC"
   },
   "outputs": [],
   "source": [
    "def showImagesWithTargets(img,targets):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    img = img.numpy()\n",
    "    plt.imshow(img)\n",
    "    plt.imshow(targets)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U4rao7QJCbjz"
   },
   "outputs": [],
   "source": [
    "def plot_error_curve(errors):\n",
    "  plt.suptitle('Learning Curve', fontsize=20)\n",
    "  plt.xlabel('Iterations', fontsize=18)\n",
    "  plt.ylabel('Classification Error', fontsize=16)\n",
    "  plt.plot(np.array(errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "Wd4bO9JpqtcK",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# Load Data Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "piF6h_W7qtcL"
   },
   "outputs": [],
   "source": [
    "def transformations(listTransforms):\n",
    "    return transforms.Compose(listTransforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "csjIkE6GqtcN"
   },
   "outputs": [],
   "source": [
    "class CudaVisionDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dir_path,transform=None):\n",
    "        super(CudaVisionDataset, self).__init__()\n",
    "        self.img_paths,self.target_paths = read_files(img_dir_path=dir_path)\n",
    "        self.transform = transform\n",
    "          \n",
    "    def __getitem__(self, index):\n",
    "        # print(index)\n",
    "        input_img = plt.imread(self.img_paths[index])\n",
    "        \n",
    "        # print(img.shape) # Shape is l x w x c\n",
    "        #input_img = input_img.reshape(3,480,640)\n",
    "        #input_img = torch.Tensor(input_img)\n",
    "        target_img = plt.imread(self.target_paths[index])\n",
    "        #target_img = target_img.reshape(3,480,640)\n",
    "        #target_img = torch.Tensor(target_img)\n",
    "        \n",
    "        #showImagesWithTargets(input_img,target_img)\n",
    "        if self.transform != None :\n",
    "            \n",
    "            trnfm_input = transformations(self.transform)\n",
    "            trnfm_target= transformations(self.transform)\n",
    "            input_img = trnfm_input(input_img)\n",
    "            target_img  = trnfm_target(target_img)\n",
    "            print(input_img.shape,target_img.shape)\n",
    "        return input_img,target_img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1ZFBT5Cymzl5"
   },
   "outputs": [],
   "source": [
    "def read_files(img_dir_path):\n",
    "    img_paths = []\n",
    "    target_paths = []\n",
    "    if os.path.isdir(img_dir_path):\n",
    "      print(\"Folder exists. Reading..\")\n",
    "    dir = os.path.join(img_dir_path,'input')\n",
    "    for r, _, f in os.walk(dir):\n",
    "      for file in f:\n",
    "            img_paths.append(os.path.join(r, file))\n",
    "    if len(img_paths) == 0:\n",
    "        print(\"No Images in given path available. Check directory or format.\")\n",
    "    dir = os.path.join(img_dir_path,'output')\n",
    "    for r, _, f in os.walk(dir):\n",
    "      for file in f:\n",
    "            target_paths.append(os.path.join(r, file))\n",
    "    if len(target_paths) == 0:\n",
    "        print(\"No Images in given path available. Check directory or format.\")\n",
    "\n",
    "    return img_paths,target_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "fj4-3YhnqtcR",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7furajqrqtcS"
   },
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "batchSize = 20\n",
    "epoch = 50\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "4HPtfqQeqtcW",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# Load Data And Make Iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "listTransforms = [transforms.ToTensor(),\n",
    "       transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                         std=[0.229, 0.224, 0.225])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "REBslww-G6BZ"
   },
   "outputs": [],
   "source": [
    "class CudaVisionDataLoader:\n",
    "\n",
    "    def __call__(self, dir_path='./small_data', transform=None,batch_size=20):\n",
    "        dataset = CudaVisionDataset(dir_path,transform)\n",
    "        return DataLoader(dataset,batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "Hdn3E4u6rQYs",
    "outputId": "5a0e0679-0ce2-42e1-ddd4-149187fdd6b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder exists. Reading..\n",
      "Folder exists. Reading..\n"
     ]
    }
   ],
   "source": [
    "#listTransforms = [transforms.RandomHorizontalFlip(0.5),\n",
    " #       transforms.ToTensor(),\n",
    "  #      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))]\n",
    "#transforms(listTransforms)\n",
    "data = CudaVisionDataLoader()\n",
    "train_loader = data.__call__(os.path.join('./small_data','train'),listTransforms,batchSize)\n",
    "test_loader = data.__call__(os.path.join('./small_data','test'),listTransforms,batchSize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FEKjakWCqtcW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 480, 640]) torch.Size([3, 120, 160])\n",
      "torch.Size([3, 480, 640]) torch.Size([3, 120, 160])\n",
      "torch.Size([3, 480, 640]) torch.Size([3, 120, 160])\n",
      "torch.Size([3, 480, 640]) torch.Size([3, 120, 160])\n",
      "torch.Size([3, 480, 640]) torch.Size([3, 120, 160])\n"
     ]
    }
   ],
   "source": [
    "dataiter = train_loader.__iter__()\n",
    "images, targets = dataiter.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "O7dcYMh5qtca",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eB8U8qs3qtcb"
   },
   "outputs": [],
   "source": [
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, original_model, outputs_indices):\n",
    "        super(ResNet18, self).__init__()\n",
    "        self.features = nn.Sequential(*list(original_model.children())[:-2])\n",
    "        self.outputs_indices = [0] + outputs_indices\n",
    "        print(self.outputs_indices)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = []\n",
    "\n",
    "        for i in range(len(self.outputs_indices) - 1):\n",
    "            x = self.features[self.outputs_indices[i]:self.outputs_indices[i + 1]](x)\n",
    "            out.append(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "class soccerSegment(nn.ModuleList):\n",
    "    def __init__(self, resnet18, outputs_indices, skips_arch, deconvs_arch, bn_arch, last_layer_arch):\n",
    "        super(soccerSegment, self).__init__()\n",
    "        self.resnet18 = ResNet18(resnet18, outputs_indices)\n",
    "        \n",
    "        # skips_arch = [64, 128, 256, 256, 0]\n",
    "        # deconvs_arch = [512, 256, 256, 128]\n",
    "        # bn_arch = [512, 512, 256]\n",
    "        # last_layer_arch = 256\n",
    "        self.skips = nn.ModuleList(\n",
    "            [nn.Conv2d(skips_arch[i], skips_arch[i + 1], kernel_size=1, stride=1, padding=0) for i in\n",
    "             range(len(skips_arch) - 2)])\n",
    "\n",
    "        self.deconvs = nn.ModuleList(\n",
    "            reversed([nn.ConvTranspose2d(deconvs_arch[i] + skips_arch[len(skips_arch) - i - 1], deconvs_arch[i + 1],\n",
    "                                         kernel_size=2, stride=2, padding=0) for i in\n",
    "                      range(len(deconvs_arch) - 1)]))\n",
    "\n",
    "        self.bns = nn.ModuleList(\n",
    "            [nn.BatchNorm2d(num_features=bn_arch[i]) for i in\n",
    "             reversed(range(len(bn_arch)))])\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.conv_det = nn.Conv2d(last_layer_arch, 3, kernel_size=1, stride=1, padding=0)\n",
    "        self.conv_seg = nn.Conv2d(last_layer_arch, 3, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        skip_links = self.resnet18(x)\n",
    "\n",
    "        for i in reversed(range(len(skip_links))):\n",
    "            if i == len(skip_links) - 1:\n",
    "                skip_links[i - 1] = torch.cat(\n",
    "                    (self.skips[i - 1](skip_links[i - 1]), self.deconvs[i - 1](self.relu(skip_links[i]))),\n",
    "                    1)\n",
    "            elif i == 0:\n",
    "                skip_links[i] = self.relu(self.bns[i](skip_links[i]))\n",
    "            else:\n",
    "                skip_links[i - 1] = torch.cat(\n",
    "                    (self.skips[i - 1](skip_links[i - 1]),\n",
    "                     self.deconvs[i - 1](self.relu(self.bns[i](skip_links[i])))),\n",
    "                    1)\n",
    "        seg = self.conv_seg(skip_links[i])\n",
    "        det = self.conv_det(skip_links[i])\n",
    "        return seg, det"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hs2mkTpfqtcd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "ltbSuwBlqtcg",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# Training Cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training cycle without hyperopt\n",
    "def train():\n",
    "    import torchvision.models as models\n",
    "    resnet18  = models.resnet18(pretrained=True)\n",
    "    model = soccerSegment(resnet18,[5,6,7,8],[64, 128, 256, 256, 0],[512, 256, 256, 128],[512, 512, 256],256)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "    for i, (images, targets) in enumerate(train_loader):\n",
    "        \n",
    "      #######################\n",
    "      #  USE GPU FOR MODEL  #\n",
    "      #######################\n",
    "      if torch.cuda.is_available():\n",
    "        images = images\n",
    "        targets = targets\n",
    "    \n",
    "    print(images.size())\n",
    "    \n",
    "      # Clear gradients w.r.t. parameters\n",
    "    optimizer.zero_grad()\n",
    "        \n",
    "      # Forward pass to get output/logits\n",
    "    detected,segmented = model(images)\n",
    "      \n",
    "    loss = criterion(detected, targets)\n",
    "        \n",
    "      # Getting gradients w.r.t. parameters\n",
    "    loss.backward()\n",
    "        \n",
    "      # Updating parameters\n",
    "    optimizer.step()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 5, 6, 7, 8]\n",
      "torch.Size([3, 480, 640]) torch.Size([3, 120, 160])\n",
      "torch.Size([3, 480, 640]) torch.Size([3, 120, 160])\n",
      "torch.Size([3, 480, 640]) torch.Size([3, 120, 160])\n",
      "torch.Size([3, 480, 640]) torch.Size([3, 120, 160])\n",
      "torch.Size([3, 480, 640]) torch.Size([3, 120, 160])\n",
      "torch.Size([5, 3, 480, 640])\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'iter' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-2da0ffaf5447>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-15-882eff824c62>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m     \u001b[0miter\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'iter' referenced before assignment"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g3Gl5b2Wqtci"
   },
   "outputs": [],
   "source": [
    "def train(args):   #Consist of all args from hyperopt\n",
    "    \n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_NCv-Jj2qtcm"
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "1wPpRNF3qtcp",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GuIweHbhqtcp"
   },
   "outputs": [],
   "source": [
    "optimizers = [torch.optim.SGD, torch.optim.Adam, torch.optim.Adagrad, torch.optim.Adadelta, torch.optim.RMSprop]\n",
    "regularizers = ['l1','l2']\n",
    "space = [hp.choice('optimizer',optimizers),hp.choice('regularizer',regularizers)]\n",
    "best_classifier = fmin(train,space,algo=tpe.suggest,max_evals=30)\n",
    "optimizer = optimizers[int(best_classifier['optimizer'])]\n",
    "regularizer = regularizers[int(best_classifier['regularizer'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bgWGV_xRqtcs"
   },
   "outputs": [],
   "source": [
    "#Use the best found optimizer and criterion\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "model = train_model(model, criterion, optimizer, exp_lr_scheduler,\n",
    "                       num_epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "ElZk6fi8qtcu",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# Visualization of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IJYeWwAHqtcu"
   },
   "outputs": [],
   "source": [
    "#I think this got covered "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "jwn8Bex5qtc0",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# Metric Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nun1TQ7jqtc1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "main.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
