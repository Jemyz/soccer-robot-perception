{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "22NKuno-qtbv",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kriBNwPMqtbz"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "import random\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from hyperopt import fmin, tpe, hp\n",
    "import time\n",
    "import copy\n",
    "import os\n",
    "from torchvision.utils import save_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "AwfgfyPdqtb4",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# Check Available Devices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_xdHa9xQqtb4",
    "outputId": "b6805a70-2f18-47f3-e7b2-ba1c4a4a831b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available:\n",
    "  avDev = torch.device(\"cuda\")\n",
    "else:\n",
    "  avDev = torch.device(\"cpu\")\n",
    "print(avDev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "r-hP4do1qtb7",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# Set Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XNpBgXb6qtb8"
   },
   "outputs": [],
   "source": [
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.backends.cudnn.deterministic=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "rtv7fnvYqtcA",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# Utility for Displaying Images, Error Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZYAs2u4UqtcC"
   },
   "outputs": [],
   "source": [
    "def showImagesWithTargets(img,targets):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    img = img.numpy()\n",
    "    plt.imshow(img)\n",
    "    plt.imshow(targets)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U4rao7QJCbjz"
   },
   "outputs": [],
   "source": [
    "def plot_error_curve(errors):\n",
    "  plt.suptitle('Learning Curve', fontsize=20)\n",
    "  plt.xlabel('Iterations', fontsize=18)\n",
    "  plt.ylabel('Classification Error', fontsize=16)\n",
    "  plt.plot(np.array(errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "Wd4bO9JpqtcK",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# Load Data Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "piF6h_W7qtcL"
   },
   "outputs": [],
   "source": [
    "def transformations(listTransforms):\n",
    "    return transforms.Compose(listTransforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "csjIkE6GqtcN"
   },
   "outputs": [],
   "source": [
    "class CudaVisionDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dir_path,transform=None):\n",
    "        super(CudaVisionDataset, self).__init__()\n",
    "        self.img_paths,self.target_paths = read_files(img_dir_path=dir_path)\n",
    "        self.transform = transform\n",
    "          \n",
    "    def __getitem__(self, index):\n",
    "        # print(index)\n",
    "        input_img = plt.imread(self.img_paths[index])\n",
    "        \n",
    "        # print(img.shape) # Shape is l x w x c\n",
    "        #input_img = input_img.reshape(3,480,640)\n",
    "        #input_img = torch.Tensor(input_img)\n",
    "        target_img = plt.imread(self.target_paths[index])\n",
    "        #target_img = target_img.reshape(3,480,640)\n",
    "        #target_img = torch.Tensor(target_img)\n",
    "        \n",
    "        #showImagesWithTargets(input_img,target_img)\n",
    "        if self.transform != None :\n",
    "            \n",
    "            trnfm_input = transformations(self.transform)\n",
    "            trnfm_target= transformations(self.transform)\n",
    "            input_img = trnfm_input(input_img)\n",
    "            target_img  = trnfm_target(target_img)\n",
    "            print(input_img.shape,target_img.shape)\n",
    "        return input_img,target_img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1ZFBT5Cymzl5"
   },
   "outputs": [],
   "source": [
    "def read_files(img_dir_path):\n",
    "    img_paths = []\n",
    "    target_paths = []\n",
    "    if os.path.isdir(img_dir_path):\n",
    "        print(\"Folder exists. Reading..\")\n",
    "    dir = os.path.join(img_dir_path,'input')\n",
    "    for r, _, f in os.walk(dir):\n",
    "        for file in f:\n",
    "            img_paths.append(os.path.join(r, file))\n",
    "    if len(img_paths) == 0:\n",
    "        print(\"No Images in given path available. Check directory or format.\")\n",
    "    dir = os.path.join(img_dir_path,'output')\n",
    "    for r, _, f in os.walk(dir):\n",
    "        for file in f:\n",
    "            target_paths.append(os.path.join(r, file))\n",
    "    if len(target_paths) == 0:\n",
    "        print(\"No Images in given path available. Check directory or format.\")\n",
    "\n",
    "    return img_paths,target_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "fj4-3YhnqtcR",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# Hyperparameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7furajqrqtcS"
   },
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "batchSize = 20\n",
    "epoch = 200\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "4HPtfqQeqtcW",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# Load Data And Make Iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "listTransforms = [transforms.ToTensor(),\n",
    "       transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                         std=[0.229, 0.224, 0.225])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "REBslww-G6BZ"
   },
   "outputs": [],
   "source": [
    "class CudaVisionDataLoader:\n",
    "\n",
    "    def __call__(self, dir_path='./small_data', transform=None,batch_size=20):\n",
    "        dataset = CudaVisionDataset(dir_path,transform)\n",
    "        return DataLoader(dataset,batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "Hdn3E4u6rQYs",
    "outputId": "5a0e0679-0ce2-42e1-ddd4-149187fdd6b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder exists. Reading..\n",
      "Folder exists. Reading..\n",
      "Folder exists. Reading..\n",
      "Folder exists. Reading..\n"
     ]
    }
   ],
   "source": [
    "#listTransforms = [transforms.RandomHorizontalFlip(0.5),\n",
    " #       transforms.ToTensor(),\n",
    "  #      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))]\n",
    "#transforms(listTransforms)\n",
    "data = CudaVisionDataLoader()\n",
    "parentDir = './small_data'\n",
    "dirDetectionDataset = os.path.join(parentDir,'detection')\n",
    "dirSegmentationDataset = os.path.join(parentDir,'segmentation')\n",
    "train_loader_detection = data.__call__(os.path.join(dirDetectionDataset,'train'),listTransforms,batchSize)\n",
    "test_loader_detection = data.__call__(os.path.join(dirDetectionDataset,'test'),listTransforms,batchSize)\n",
    "train_loader_segmentation = data.__call__(os.path.join(dirSegmentationDataset,'train'),listTransforms,batchSize)\n",
    "test_loader_segmentation = data.__call__(os.path.join(dirSegmentationDataset,'test'),listTransforms,batchSize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FEKjakWCqtcW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 600, 800]) torch.Size([3, 150, 200])\n",
      "torch.Size([3, 600, 800]) torch.Size([3, 150, 200])\n",
      "torch.Size([3, 600, 800]) torch.Size([3, 150, 200])\n",
      "torch.Size([3, 600, 800]) torch.Size([3, 150, 200])\n",
      "torch.Size([3, 480, 640]) torch.Size([3, 120, 160])\n",
      "torch.Size([3, 480, 640]) torch.Size([3, 120, 160])\n",
      "torch.Size([3, 600, 800]) torch.Size([3, 150, 200])\n",
      "torch.Size([3, 600, 800]) torch.Size([3, 150, 200])\n",
      "torch.Size([3, 480, 640]) torch.Size([3, 120, 160])\n",
      "torch.Size([3, 600, 800]) torch.Size([3, 150, 200])\n",
      "torch.Size([3, 480, 640]) torch.Size([3, 120, 160])\n",
      "torch.Size([3, 600, 800]) torch.Size([3, 150, 200])\n",
      "torch.Size([3, 480, 640]) torch.Size([3, 120, 160])\n",
      "torch.Size([3, 480, 640]) torch.Size([3, 120, 160])\n",
      "torch.Size([3, 480, 640]) torch.Size([3, 120, 160])\n",
      "torch.Size([3, 480, 640]) torch.Size([3, 120, 160])\n",
      "torch.Size([3, 600, 800]) torch.Size([3, 150, 200])\n",
      "torch.Size([3, 600, 800]) torch.Size([3, 150, 200])\n",
      "torch.Size([3, 480, 640]) torch.Size([3, 120, 160])\n",
      "torch.Size([3, 480, 640]) torch.Size([3, 120, 160])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 0: Sizes of tensors must match except in dimension 0. Got 600 and 480 in dimension 2 at C:\\w\\1\\s\\tmp_conda_3.7_100118\\conda\\conda-bld\\pytorch_1579082551706\\work\\aten\\src\\TH/generic/THTensor.cpp:612",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-f2f3cdf9c9a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdataiter_detection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_loader_detection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataiter_detection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdataiter_segmentation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_loader_segmentation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataiter_segmentation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    383\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 385\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    386\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'numpy'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'string_'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: invalid argument 0: Sizes of tensors must match except in dimension 0. Got 600 and 480 in dimension 2 at C:\\w\\1\\s\\tmp_conda_3.7_100118\\conda\\conda-bld\\pytorch_1579082551706\\work\\aten\\src\\TH/generic/THTensor.cpp:612"
     ]
    }
   ],
   "source": [
    "dataiter_detection = train_loader_detection.__iter__()\n",
    "images, targets = dataiter_detection.next()\n",
    "dataiter_segmentation = train_loader_segmentation.__iter__()\n",
    "images,targets = dataiter_segmentation.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "O7dcYMh5qtca",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eB8U8qs3qtcb"
   },
   "outputs": [],
   "source": [
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, original_model, outputs_indices):\n",
    "        super(ResNet18, self).__init__()\n",
    "        self.features = nn.Sequential(*list(original_model.children())[:-2])\n",
    "        self.outputs_indices = [0] + outputs_indices\n",
    "        print(self.outputs_indices)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = []\n",
    "\n",
    "        for i in range(len(self.outputs_indices) - 1):\n",
    "            x = self.features[self.outputs_indices[i]:self.outputs_indices[i + 1]](x)\n",
    "            out.append(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "class soccerSegment(nn.ModuleList):\n",
    "    def __init__(self, resnet18, outputs_indices, skips_arch, deconvs_arch, bn_arch, last_layer_arch):\n",
    "        super(soccerSegment, self).__init__()\n",
    "        self.resnet18 = ResNet18(resnet18, outputs_indices)\n",
    "        \n",
    "        # skips_arch = [64, 128, 256, 256, 0]\n",
    "        # deconvs_arch = [512, 256, 256, 128]\n",
    "        # bn_arch = [512, 512, 256]\n",
    "        # last_layer_arch = 256\n",
    "        self.skips = nn.ModuleList(\n",
    "            [nn.Conv2d(skips_arch[i], skips_arch[i + 1], kernel_size=1, stride=1, padding=0) for i in\n",
    "             range(len(skips_arch) - 2)])\n",
    "\n",
    "        self.deconvs = nn.ModuleList(\n",
    "            reversed([nn.ConvTranspose2d(deconvs_arch[i] + skips_arch[len(skips_arch) - i - 1], deconvs_arch[i + 1],\n",
    "                                         kernel_size=2, stride=2, padding=0) for i in\n",
    "                      range(len(deconvs_arch) - 1)]))\n",
    "\n",
    "        self.bns = nn.ModuleList(\n",
    "            [nn.BatchNorm2d(num_features=bn_arch[i]) for i in\n",
    "             reversed(range(len(bn_arch)))])\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.conv_det = nn.Conv2d(last_layer_arch, 3, kernel_size=1, stride=1, padding=0)\n",
    "        self.conv_seg = nn.Conv2d(last_layer_arch, 3, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        skip_links = self.resnet18(x)\n",
    "\n",
    "        for i in reversed(range(len(skip_links))):\n",
    "            if i == len(skip_links) - 1:\n",
    "                skip_links[i - 1] = torch.cat(\n",
    "                    (self.skips[i - 1](skip_links[i - 1]), self.deconvs[i - 1](self.relu(skip_links[i]))),\n",
    "                    1)\n",
    "            elif i == 0:\n",
    "                skip_links[i] = self.relu(self.bns[i](skip_links[i]))\n",
    "            else:\n",
    "                skip_links[i - 1] = torch.cat(\n",
    "                    (self.skips[i - 1](skip_links[i - 1]),\n",
    "                     self.deconvs[i - 1](self.relu(self.bns[i](skip_links[i])))),\n",
    "                    1)\n",
    "        seg = self.conv_seg(skip_links[i])\n",
    "        det = self.conv_det(skip_links[i])\n",
    "        return seg, det"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hs2mkTpfqtcd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "ltbSuwBlqtcg",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# Training Cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training cycle without hyperopt\n",
    "def train():\n",
    "    import torchvision.models as models\n",
    "    resnet18  = models.resnet18(pretrained=True)\n",
    "    model = soccerSegment(resnet18,[5,6,7,8],[64, 128, 256, 256, 0],[512, 256, 256, 128],[512, 512, 256],256)\n",
    "    #if torch.cuda.is_available():\n",
    "     #   model.cuda()\n",
    "    iter = 0\n",
    "    criterionDetection = nn.MSELoss()\n",
    "    criterionSegmented = nn.NLLLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "    for i,(images,targets) in enumerate(train_loader_detection):\n",
    "      #  if torch.cuda.is_available():\n",
    "       #     images = images.cuda()\n",
    "        #    targets = targets.cuda()\n",
    "\n",
    "    \n",
    "      # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "      # Forward pass to get output\n",
    "        detected,segmented = model(images)\n",
    "        target = torch.argmax(targets, 1)\n",
    "        loss = criterionDetection(detected, targets)\n",
    "        \n",
    "      # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "        \n",
    "      # Updating parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "    for i,(images,targets) in enumerate(train_loader_segmentation):\n",
    "        #if torch.cuda.is_available():\n",
    "         #   images = images.cuda()\n",
    "          #  targets = targets.cuda()\n",
    "\n",
    "    \n",
    "      # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "      # Forward pass to get output\n",
    "        detected,segmented = model(images)\n",
    "        print(\"The segmented size\")\n",
    "        print(segmented.size())\n",
    "        target = torch.argmax(targets, 1)\n",
    "        loss = criterionSegmented(segmented, target)\n",
    "        \n",
    "      # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "        \n",
    "      # Updating parameters\n",
    "        optimizer.step()\n",
    "        iter += 1\n",
    "    losses =0\n",
    "    if iter % 10 == 0:\n",
    "          # Iterate through test dataset\n",
    "        for images, targets in test_loader_detection:\n",
    "              #######################\n",
    "              #  USE GPU FOR MODEL  #\n",
    "              #######################\n",
    "           # if torch.cuda.is_available():\n",
    "            #    images = images.cuda()\n",
    "                \n",
    "              # Forward pass only to get logits/output\n",
    "\n",
    "            detected,segmented = model(images)\n",
    "              \n",
    "              \n",
    "              # Total number of labels\n",
    "            loss=criterionDetection(detected, targets)\n",
    "            losses = losses+loss.item()    \n",
    "            \n",
    "          # Print Loss\n",
    "        print('Loss Detection: {}.', loss.item())\n",
    "        imageToSave = detected[0]\n",
    "        save_image(imageToSave, './outputs/detected/img[' + str(iter) + '].png')\n",
    "        losses =0\n",
    "        for images, targets in test_loader_segmentation:\n",
    "              #######################\n",
    "              #  USE GPU FOR MODEL  #\n",
    "              #######################\n",
    "            #if torch.cuda.is_available():\n",
    "                #images = images.cuda()\n",
    "                \n",
    "              # Forward pass only to get logits/output\n",
    "\n",
    "            detected,segmented = model(images)\n",
    "              \n",
    "              \n",
    "              # Total number of labels\n",
    "            target = torch.argmax(targets, 1)\n",
    "            loss=criterionSegmented(segmented, target)\n",
    "            losses = losses+loss.item()    \n",
    "            \n",
    "          # Print Loss\n",
    "        print('Loss Segmentation: {}.', loss.item())\n",
    "        #Save some images to check\n",
    "        imageToSave = segmented[0]\n",
    "        save_image(imageToSave, './outputs/segmented/img[' + str(iter) + '].png')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g3Gl5b2Wqtci"
   },
   "outputs": [],
   "source": [
    "def train(args):   #Consist of all args from hyperopt\n",
    "    \n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_NCv-Jj2qtcm"
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "1wPpRNF3qtcp",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GuIweHbhqtcp"
   },
   "outputs": [],
   "source": [
    "optimizers = [torch.optim.SGD, torch.optim.Adam, torch.optim.Adagrad, torch.optim.Adadelta, torch.optim.RMSprop]\n",
    "regularizers = ['l1','l2']\n",
    "space = [hp.choice('optimizer',optimizers),hp.choice('regularizer',regularizers)]\n",
    "best_classifier = fmin(train,space,algo=tpe.suggest,max_evals=30)\n",
    "optimizer = optimizers[int(best_classifier['optimizer'])]\n",
    "regularizer = regularizers[int(best_classifier['regularizer'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bgWGV_xRqtcs"
   },
   "outputs": [],
   "source": [
    "#Use the best found optimizer and criterion\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "model = train_model(model, criterion, optimizer, exp_lr_scheduler,\n",
    "                       num_epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "ElZk6fi8qtcu",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# Visualization of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IJYeWwAHqtcu"
   },
   "outputs": [],
   "source": [
    "#I think this got covered "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "jwn8Bex5qtc0",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# Metric Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nun1TQ7jqtc1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "main.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
