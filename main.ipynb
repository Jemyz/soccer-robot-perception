{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "22NKuno-qtbv",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kriBNwPMqtbz",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "import random\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from hyperopt import fmin, tpe, hp\n",
    "import time\n",
    "import copy\n",
    "import os\n",
    "from torchvision.utils import save_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "AwfgfyPdqtb4",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# Check Available Devices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_xdHa9xQqtb4",
    "outputId": "b6805a70-2f18-47f3-e7b2-ba1c4a4a831b",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available:\n",
    "  avDev = torch.device(\"cuda\")\n",
    "else:\n",
    "  avDev = torch.device(\"cpu\")\n",
    "print(avDev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "r-hP4do1qtb7",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# Set Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XNpBgXb6qtb8",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.backends.cudnn.deterministic=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "rtv7fnvYqtcA",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# Utility for Displaying Images, Error Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZYAs2u4UqtcC",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def showImagesWithTargets(img,targets):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    img = img.numpy()\n",
    "    plt.imshow(img.transpose((1,2,0)))\n",
    "    plt.show()\n",
    "    targets=targets.numpy()\n",
    "    plt.imshow(targets.transpose((1,2,0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#Visualise segmented output\n",
    "def visualiseSegmented(segmentedImage,iter):\n",
    "    colorMap = [[0,0,0],[0,0,255],[255,255,255]]\n",
    "    size = segmentedImage.size()\n",
    "    segImage = np.empty([3,size[0],size[1]])\n",
    "    for i in range(size[0]):\n",
    "        for j in range(size[1]):\n",
    "            color = colorMap[segmentedImage[i][j]]\n",
    "            for k in range(3):\n",
    "                segImage[k,i,j] = color[k]\n",
    "    segImage = segImage.transpose((1,2,0))\n",
    "    plt.imshow(segImage)\n",
    "    plt.savefig('./outputs/segmented/img[' + str(iter) + '].png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U4rao7QJCbjz",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_error_curve(errors):\n",
    "  plt.suptitle('Learning Curve', fontsize=20)\n",
    "  plt.xlabel('Iterations', fontsize=18)\n",
    "  plt.ylabel('Classification Error', fontsize=16)\n",
    "  plt.plot(np.array(errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "Wd4bO9JpqtcK",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# Load Data Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "piF6h_W7qtcL",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def transformations(listTransforms):\n",
    "    return transforms.Compose(listTransforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "csjIkE6GqtcN",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class CudaVisionDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dir_path,transform=None):\n",
    "        super(CudaVisionDataset, self).__init__()\n",
    "        self.img_paths,self.target_paths = read_files(img_dir_path=dir_path)\n",
    "        self.transform = transform\n",
    "          \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        input_img = plt.imread(self.img_paths[index])\n",
    "        # print(img.shape) # Shape is l x w x c\n",
    "        #input_img = input_img.reshape(3,480,640)\n",
    "        #input_img = torch.Tensor(input_img)\n",
    "        target_img = plt.imread(self.target_paths[index])\n",
    "        #target_img = target_img.reshape(3,480,640)\n",
    "        #target_img = torch.Tensor(target_img)\n",
    "        \n",
    "        #showImagesWithTargets(input_img,target_img)\n",
    "        if self.transform != None :\n",
    "            \n",
    "            trnfm_input = transformations(self.transform)\n",
    "            trnfm_target= transformations(self.transform)\n",
    "            input_img = trnfm_input(input_img)\n",
    "            target_img  = trnfm_target(target_img)\n",
    "            #print(input_img.shape,target_img.shape)\n",
    "        return input_img,target_img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1ZFBT5Cymzl5",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def read_files(img_dir_path):\n",
    "    img_paths = []\n",
    "    target_paths = []\n",
    "    if os.path.isdir(img_dir_path):\n",
    "        print(\"Folder exists. Reading..\")\n",
    "    dir = os.path.join(img_dir_path,'input')\n",
    "    for r, _, f in os.walk(dir):\n",
    "        for file in f:\n",
    "            img_paths.append(os.path.join(r, file))\n",
    "            \n",
    "    if len(img_paths) == 0:\n",
    "        print(\"No Images in given path available. Check directory or format.\")\n",
    "    dir = os.path.join(img_dir_path,'output')\n",
    "    for r, _, f in os.walk(dir):\n",
    "        for file in f:\n",
    "            target_paths.append(os.path.join(r, file))\n",
    "    if len(target_paths) == 0:\n",
    "        print(\"No Images in given path available. Check directory or format.\")\n",
    "    \n",
    "    return img_paths,target_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "fj4-3YhnqtcR",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# Hyperparameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7furajqrqtcS",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "lr = 0.0001\n",
    "batchSize = 20\n",
    "epoch = 200\n",
    "tv_weight = 0.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "4HPtfqQeqtcW",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# Load Data And Make Iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "listTransforms = [transforms.ToTensor(),transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                         std=[0.229, 0.224, 0.225])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "REBslww-G6BZ",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class CudaVisionDataLoader:\n",
    "\n",
    "    def __call__(self, dir_path='./small_data', transform=None,batch_size=20):\n",
    "        dataset = CudaVisionDataset(dir_path,transform)\n",
    "        return DataLoader(dataset,batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "Hdn3E4u6rQYs",
    "outputId": "5a0e0679-0ce2-42e1-ddd4-149187fdd6b9",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder exists. Reading..\n",
      "Folder exists. Reading..\n",
      "Folder exists. Reading..\n",
      "Folder exists. Reading..\n"
     ]
    }
   ],
   "source": [
    "#listTransforms = [transforms.RandomHorizontalFlip(0.5),\n",
    " #       transforms.ToTensor(),\n",
    "  #      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))]\n",
    "#transforms(listTransforms)\n",
    "data = CudaVisionDataLoader()\n",
    "parentDir = './small_data'\n",
    "dirDetectionDataset = os.path.join(parentDir,'detection')\n",
    "dirSegmentationDataset = os.path.join(parentDir,'segmentation')\n",
    "train_loader_detection = data.__call__(os.path.join(dirDetectionDataset,'train'),listTransforms,batchSize)\n",
    "test_loader_detection = data.__call__(os.path.join(dirDetectionDataset,'test'),listTransforms,batchSize)\n",
    "train_loader_segmentation = data.__call__(os.path.join(dirSegmentationDataset,'train'),listTransforms,batchSize)\n",
    "test_loader_segmentation = data.__call__(os.path.join(dirSegmentationDataset,'test'),listTransforms,batchSize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FEKjakWCqtcW",
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          ...,\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489]],\n",
      "\n",
      "         [[2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          ...,\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286]],\n",
      "\n",
      "         [[2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          ...,\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400]]],\n",
      "\n",
      "\n",
      "        [[[2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          ...,\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489]],\n",
      "\n",
      "         [[2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          ...,\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286]],\n",
      "\n",
      "         [[2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          ...,\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400]]],\n",
      "\n",
      "\n",
      "        [[[2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          ...,\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489]],\n",
      "\n",
      "         [[2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          ...,\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286]],\n",
      "\n",
      "         [[2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          ...,\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400]]],\n",
      "\n",
      "\n",
      "        [[[2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          ...,\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489]],\n",
      "\n",
      "         [[2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          ...,\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286]],\n",
      "\n",
      "         [[2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          ...,\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400]]],\n",
      "\n",
      "\n",
      "        [[[2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          ...,\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489]],\n",
      "\n",
      "         [[2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          ...,\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286]],\n",
      "\n",
      "         [[2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          ...,\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400]]]])\n"
     ]
    }
   ],
   "source": [
    "dataiter_detection = train_loader_detection.__iter__()\n",
    "\n",
    "dataiter_segmentation = train_loader_segmentation.__iter__()\n",
    "images, targets = dataiter_detection.next()\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "O7dcYMh5qtca",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eB8U8qs3qtcb",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, original_model, outputs_indices):\n",
    "        super(ResNet18, self).__init__()\n",
    "        self.features = nn.Sequential(*list(original_model.children())[:-2])\n",
    "        self.outputs_indices = [0] + outputs_indices\n",
    "        print(self.outputs_indices)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = []\n",
    "\n",
    "        for i in range(len(self.outputs_indices) - 1):\n",
    "            x = self.features[self.outputs_indices[i]:self.outputs_indices[i + 1]](x)\n",
    "            out.append(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "class soccerSegment(nn.ModuleList):\n",
    "    def __init__(self, resnet18, outputs_indices, skips_arch, deconvs_arch, bn_arch, last_layer_arch):\n",
    "        super(soccerSegment, self).__init__()\n",
    "        self.resnet18 = ResNet18(resnet18, outputs_indices)\n",
    "        \n",
    "        # skips_arch = [64, 128, 256, 256, 0]\n",
    "        # deconvs_arch = [512, 256, 256, 128]\n",
    "        # bn_arch = [512, 512, 256]\n",
    "        # last_layer_arch = 256\n",
    "        self.skips = nn.ModuleList(\n",
    "            [nn.Conv2d(skips_arch[i], skips_arch[i + 1], kernel_size=1, stride=1, padding=0) for i in\n",
    "             range(len(skips_arch) - 2)])\n",
    "\n",
    "        self.deconvs = nn.ModuleList(\n",
    "            reversed([nn.ConvTranspose2d(deconvs_arch[i] + skips_arch[len(skips_arch) - i - 1], deconvs_arch[i + 1],\n",
    "                                         kernel_size=2, stride=2, padding=0) for i in\n",
    "                      range(len(deconvs_arch) - 1)]))\n",
    "\n",
    "        self.bns = nn.ModuleList(\n",
    "            [nn.BatchNorm2d(num_features=bn_arch[i]) for i in\n",
    "             reversed(range(len(bn_arch)))])\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.conv_det = nn.Conv2d(last_layer_arch, 3, kernel_size=1, stride=1, padding=0)\n",
    "        self.conv_seg = nn.Conv2d(last_layer_arch, 3, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        skip_links = self.resnet18(x)\n",
    "\n",
    "        for i in reversed(range(len(skip_links))):\n",
    "            if i == len(skip_links) - 1:\n",
    "                skip_links[i - 1] = torch.cat(\n",
    "                    (self.skips[i - 1](skip_links[i - 1]), self.deconvs[i - 1](self.relu(skip_links[i]))),\n",
    "                    1)\n",
    "            elif i == 0:\n",
    "                skip_links[i] = self.relu(self.bns[i](skip_links[i]))\n",
    "            else:\n",
    "                skip_links[i - 1] = torch.cat(\n",
    "                    (self.skips[i - 1](skip_links[i - 1]),\n",
    "                     self.deconvs[i - 1](self.relu(self.bns[i](skip_links[i])))),\n",
    "                    1)\n",
    "        seg = self.conv_seg(skip_links[i])\n",
    "        det = self.conv_det(skip_links[i])\n",
    "        return seg, det"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hs2mkTpfqtcd",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "ltbSuwBlqtcg",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# Training Cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#Metrics \n",
    "\n",
    "def segmentationAccuracy(segmented,targets):\n",
    "    sizes = segmented.size()\n",
    "    \n",
    "    total_pixel = sizes[0] * sizes[2] *sizes[3]\n",
    "    \n",
    "    segmented = torch.argmax(segmented, 1)\n",
    "    difference = torch.abs(segmented-targets)\n",
    "    same =(difference==0).sum()\n",
    "    \n",
    "    accuracy = (same.item())/total_pixel *100\n",
    "    return accuracy\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class TVLoss(nn.Module):\n",
    "    def __init__(self,TVLoss_weight=1):\n",
    "        super(TVLoss,self).__init__()\n",
    "        self.TVLoss_weight = TVLoss_weight\n",
    "\n",
    "    def forward(self,x):\n",
    "        batch_size = x.size()[0]\n",
    "        h_x = x.size()[2]\n",
    "        w_x = x.size()[3]\n",
    "        count_h = self._tensor_size(x[:,:,1:,:])\n",
    "        count_w = self._tensor_size(x[:,:,:,1:])\n",
    "        h_tv = torch.pow((x[:,:,1:,:]-x[:,:,:h_x-1,:]),2).sum()\n",
    "        w_tv = torch.pow((x[:,:,:,1:]-x[:,:,:,:w_x-1]),2).sum()\n",
    "        return self.TVLoss_weight*2*(h_tv/count_h+w_tv/count_w)/batch_size\n",
    "\n",
    "    def _tensor_size(self,t):\n",
    "        return t.size()[1]*t.size()[2]*t.size()[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#Training cycle without hyperopt\n",
    "def train():\n",
    "    import torchvision.models as models\n",
    "    resnet18  = models.resnet18(pretrained=True)\n",
    "    model = soccerSegment(resnet18,[5,6,7,8],[64, 128, 256, 256, 0],[512, 256, 256, 128],[512, 512, 256],256)\n",
    "    #if torch.cuda.is_available():\n",
    "     #   model.cuda()\n",
    "    iter = 0\n",
    "    criterionDetection = nn.MSELoss()\n",
    "    criterionSegmented = nn.NLLLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "    for num in range(2):\n",
    "        try:\n",
    "            images, targets = dataiter_detection.next()\n",
    "          #  if torch.cuda.is_available():\n",
    "           #     images = images.cuda()\n",
    "            #    targets = targets.cuda()\n",
    "\n",
    "        except:\n",
    "            dataiter_detection = train_loader_detection.__iter__()\n",
    "            images,targets = dataiter_detection.next()\n",
    "          # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "          # Forward pass to get output\n",
    "        detected,segmented = model(images)\n",
    "        imageToSave = detected[0]\n",
    "        imageToSave = imageToSave.detach().numpy()\n",
    "        save_image(detected[0], './img[' + str(iter) + '].png')\n",
    "        loss = criterionDetection(detected, targets)\n",
    "        addition = TVLoss(tv_weight)\n",
    "        lossTV = addition(targets)\n",
    "        total_loss = loss + lossTV\n",
    "          # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "          # Updating parameters\n",
    "        optimizer.step()\n",
    "        try:\n",
    "            images,targets = dataiter_segmentation.next()\n",
    "            #if torch.cuda.is_available():\n",
    "             #   images = images.cuda()\n",
    "              #  targets = targets.cuda()\n",
    "        except:\n",
    "            dataiter_segmentation = train_loader_segmentation.__iter__()\n",
    "            images,targets = dataiter_segmentation.next()\n",
    "          \n",
    "\n",
    "          # Forward pass to get output\n",
    "        detected,segmented = model(images)\n",
    "        target = torch.argmax(targets, 1)\n",
    "        loss = criterionSegmented(segmented, target)\n",
    "        showImagesWithTargets(images[0],targets[0])\n",
    "          # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "          # Updating parameters\n",
    "        optimizer.step()\n",
    "        iter += 1\n",
    "        losses =0\n",
    "        if iter % 1 == 0:\n",
    "              # Iterate through test dataset\n",
    "            for images, targets in test_loader_detection:\n",
    "                  #######################\n",
    "                  #  USE GPU FOR MODEL  #\n",
    "                  #######################\n",
    "               # if torch.cuda.is_available():\n",
    "                #    images = images.cuda()\n",
    "\n",
    "                  # Forward pass only to get logits/output\n",
    "\n",
    "                detected,segmented = model(images)\n",
    "\n",
    "\n",
    "                  # Total number of labels\n",
    "                loss=criterionDetection(detected, targets)\n",
    "                losses = losses+loss.item()    \n",
    "\n",
    "              # Print Loss\n",
    "            print('Loss Detection: {}.', loss.item())\n",
    "            \n",
    "            losses =0\n",
    "            for images, targets in test_loader_segmentation:\n",
    "                  #######################\n",
    "                  #  USE GPU FOR MODEL  #\n",
    "                  #######################\n",
    "                #if torch.cuda.is_available():\n",
    "                    #images = images.cuda()\n",
    "\n",
    "                  # Forward pass only to get logits/output\n",
    "                #print(targets[0][0])\n",
    "                detected,segmented = model(images)\n",
    "\n",
    "\n",
    "                  # Total number of labels\n",
    "                target = torch.argmax(targets, 1)\n",
    "                loss=criterionSegmented(segmented, target)\n",
    "                losses = losses+loss.item()    \n",
    "\n",
    "              # Print Loss\n",
    "            print('Loss Segmentation: {}.', loss.item())\n",
    "            accuracy =segmentationAccuracy(segmented,target)\n",
    "            print('Segmentation Accuracy: {}.',accuracy)\n",
    "            #Save some images to check\n",
    "            segmented = torch.argmax(segmented, 1)\n",
    "            visualiseSegmented(segmented[0],iter)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 5, 6, 7, 8]\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'dataiter_detection' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-166-2da0ffaf5447>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-159-ed245ca427a9>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mcriterionSegmented\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNLLLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataiter_detection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mnum\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'dataiter_detection' referenced before assignment"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g3Gl5b2Wqtci",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def train(args):   #Consist of all args from hyperopt\n",
    "    \n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_NCv-Jj2qtcm",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "1wPpRNF3qtcp",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GuIweHbhqtcp",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "optimizers = [torch.optim.SGD, torch.optim.Adam, torch.optim.Adagrad, torch.optim.Adadelta, torch.optim.RMSprop]\n",
    "regularizers = ['l1','l2']\n",
    "space = [hp.choice('optimizer',optimizers),hp.choice('regularizer',regularizers)]\n",
    "best_classifier = fmin(train,space,algo=tpe.suggest,max_evals=30)\n",
    "optimizer = optimizers[int(best_classifier['optimizer'])]\n",
    "regularizer = regularizers[int(best_classifier['regularizer'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bgWGV_xRqtcs",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#Use the best found optimizer and criterion\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "model = train_model(model, criterion, optimizer, exp_lr_scheduler,\n",
    "                       num_epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "ElZk6fi8qtcu",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# Visualization of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IJYeWwAHqtcu",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#I think this got covered "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "jwn8Bex5qtc0",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# Metric Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nun1TQ7jqtc1",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def seg_iou(ground_truth, predicted, classes):\n",
    "    avg_iou = 0\n",
    "    for c in classes:\n",
    "        gt = np.all(ground_truth == c, axis=-1)\n",
    "        pr = np.all(predicted == c, axis=-1)\n",
    "        intersection = np.logical_and(gt, pr)\n",
    "        union = np.logical_or(gt, pr)\n",
    "        iou_score = np.sum(intersection) / np.sum(union)\n",
    "\n",
    "        avg_iou += iou_score\n",
    "    return avg_iou\n",
    "def det_recall(ground_truth, predicted, classes, tolerance=0.00):\n",
    "    avg_recall = 0\n",
    "    for c in classes:\n",
    "        gt = np.all(ground_truth == c, axis=-1)\n",
    "        pr = np.all(predicted == c, axis=-1)\n",
    "        intersection = np.logical_and(gt, pr)\n",
    "        recall_score = np.sum(intersection) / (np.sum(gt) + tolerance)\n",
    "\n",
    "        avg_recall += recall_score\n",
    "    return avg_recall\n",
    "\n",
    "\n",
    "def det_precision(ground_truth, predicted, classes, tolerance=0.00):\n",
    "    avg_precision = 0\n",
    "    for c in classes:\n",
    "        gt = np.all(ground_truth == c, axis=-1)\n",
    "        pr = np.all(predicted == c, axis=-1)\n",
    "        intersection = np.logical_and(gt, pr)\n",
    "        precision_score = np.sum(intersection) / (np.sum(pr) + tolerance)\n",
    "\n",
    "        avg_precision += precision_score\n",
    "    return avg_precision\n",
    "\n",
    "\n",
    "def det_f1score(precision, recall, tolerance=0.00):\n",
    "    return (precision * recall) / (precision + recall + tolerance)\n",
    "\n",
    "\n",
    "def det_false_rate(ground_truth, predicted, classes, tolerance=0.00):\n",
    "    avg_false_rate = 0\n",
    "    for c in classes:\n",
    "        gt = np.all(ground_truth == c, axis=-1)\n",
    "        pr = np.all(predicted == c, axis=-1)\n",
    "        intersection = np.logical_and(gt, pr)\n",
    "        union = np.logical_or(gt, pr)\n",
    "        false_rate_score = 1 - (np.sum(intersection) / (np.sum(union) + tolerance))\n",
    "\n",
    "        avg_false_rate += false_rate_score\n",
    "    return avg_false_rate\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "main.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
